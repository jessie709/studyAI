{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"numpy version is 1.17.2\n    pandas version is 0.25.1\nmatplotlib version is 3.1.1\n    opencv version is 3.4.1\n"}],"source":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nimport cv2\nimport re\n\nmpl.rcParams['font.sans-serif'] = ['SimHei']\n%matplotlib inline\n\nfor lib in [('numpy',np), ('pandas', pd), ('matplotlib', mpl), ('opencv', cv2)]:\n    print(f'{lib[0]:>10} version is {lib[1].__version__}')"},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":"def test_train_file_names(k, d):\n    \"\"\"\n    将指定目录下的文件分组，每组随机提取 k 比率的文件作为训练集，其余的作为测试集。\n    注意：该函数只对文件名操作，并非实际对文件操作\n    \n    Paramaters\n    -----------\n    k -- 训练集所占比率 0<k<=1\n    d -- 存放文件的目录\n    \n    Returns\n    -------\n    ndarray 1-D 训练集\n    ndarray 1-D 测试集\n    \"\"\"\n    # 构建的DataFrame的字段名称\n    FILE_NAME = 'file_name'\n    FILE_GROUP_NAME = 'file_group_name'\n    # 获取文件列表\n    fn_list = os.listdir(d)\n    # 根据文件列表创建 DataFrame\n    df = pd.DataFrame(fn_list, columns=[FILE_NAME])\n    # 增加文件文组标示\n    # extract 的说明: 根据正则表达式 r'(.*)(_)' 提取字符串\n    #                比如: 's1_1.bmp' -> ('s1', '_')\n    #                     's10_10.bmp' -> ('s10', '_')\n    df[FILE_GROUP_NAME] = df.file_name.str.extract(r'(.*)(_)')[0]\n    # 根据 FILE_GROUP_NAME 进行分组, 得到分组对象 grouped\n    # 分组对象 grouded 的 groups 属性是一个字典, key 是分组名称, value 是分组数据(row index)\n    # 形如: {'s1': [1,2,3,...], 's2': [10,11,12...]}\n    grouped = df.groupby([FILE_GROUP_NAME])\n    train_set = np.array([])\n    test_set = np.array([])\n    # 循环所有分组数据, 每次操作一组数据\n    for v in grouped.groups.values():\n        # 从 DF 中获取 file_name 字段 的数据\n        # v 是 row index.\n        data = df[FILE_NAME][v]\n        # 随机获取指定比率的数据 作为训练集(文件名称)\n        train = data.sample(frac=k)\n        # 提取剩余数据 作为测试集(文件名称)\n        test = data.drop(train.index)\n        # 将一组中的随机提取的训练集数据放入总训练集中\n        train_set = np.concatenate((train_set, train.values))\n        # 将一组中的测试集数据放入总测试集中\n        test_set = np.concatenate((test_set, test.values))\n    return train_set, test_set\n\ndef img2vector(img_file_path_name):\n    \"\"\"\n    图片向量化\n    将给定的图片(m, n), 输出(1, m*n)的行向量\n    \"\"\"\n    img = cv2.imread(img_file_path_name, 0)\n    return img.flatten().reshape(1, -1)\n\ndef load_orl(k, d):\n    \"\"\"\n    加载图片文件形成 matrix\n    \n    Parameters\n    ----------\n    k {float} -- 图片文件训练集比率 0 < k <= 1\n    d {string} -- 图片文件所在目录\n    \n    Returns\n    -------\n    {ndarray 2D} -- 训练集(特征)\n    {ndarray 2D} -- 训练集(标签/真实值)\n    {ndarray 2D} -- 测试集(特征)\n    {ndarray 2D} -- 测试集(标签/真实值)\n    \"\"\"\n    # 图片文件拆分为 训练集用文件 测试集用文件\n    train_file_names, test_file_names = test_train_file_names(k, d)\n    # 生成测试集第一条数据\n    train_set = img2vector(os.path.join(d, train_file_names[0]))\n    # 生成测试集第一个标签\n    train_label = np.array([re.sub('_.*', '', train_file_names[0])])\n    # 生成训练集第一条数据\n    test_set = img2vector(os.path.join(d, test_file_names[0]))\n    # 生成训练集第一个标签\n    test_label = np.array([re.sub('_.*', '', test_file_names[0])])\n    # 循环生成训练集数据和训练集标签\n    # 因为第一条数据已经生成过, 因此需要从第二条开始循环\n    for f in train_file_names[1:]:\n        img = img2vector(os.path.join(d, f))\n        train_set = np.concatenate((train_set, img))\n        train_label = np.append(train_label, re.sub('_.*', '', f))\n    # 循环生成测试集数据和训练集标签\n    # 因为第一条数据已经生成过, 因此需要从第二条开始循环\n    for f in test_file_names[1:]:\n        img = img2vector(os.path.join(d, f))\n        test_set = np.concatenate((test_set, img))\n        test_label = np.append(test_label, re.sub('_.*', '', f))\n    return train_set, train_label, test_set, test_label\n\ndef PCA(data, r):\n    \"\"\"\n    Principle Component Analysis (PCA) 主成分分析 算法\n\n    Parameters\n    ---------\n    data {ndarray 2D} -- 原数据\n    r {int} -- 保留维度\n\n    Returns\n    -------\n    {ndarray 2D} -- PCA结果\n    {ndarray 2D} -- 协方差矩阵\n    {ndarray 1D} -- 协方差矩阵特征值\n    {ndarray 2D} -- 协方差矩阵特征向量\n    \"\"\"\n    # 原始数据的记录量，即行的数量\n    rows = data.shape[0]\n    # 复制一份原数据并进行转置\n    # 转置后的矩阵每行代表一个特征，每列代表一条记录（一张图片）\n    X = np.copy(data).T\n    # 按行计算平均值\n    mu = X.mean(axis=1)[:, None]\n    # 按行平句话\n    A = X - mu\n    C = (A @ A.T) / rows\n    D, V = np.linalg.eig(C)\n    idx = D.argsort()[::-1]\n    D = D[idx]\n    V = V[:, idx]\n    P = V.T\n    return P, C, D, V"}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}