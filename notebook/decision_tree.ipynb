{"cells":[{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":"# Decision Tree\n\n决策树的难点在于如何决定对属性进行划分的顺序, 比如下面的例子, root node 应该选哪个属性(色泽?根蒂?...)呢? 对于这个问题决策树给出了最为通用的三种算法:\n\n- 信息增益(ID3)\n- 信息增益率(C4.5)\n- 基尼系数(CART)\n\n下面对这三种算法做详细的介绍.\n\n为了更好的理解算法, 我们设计了一份数据, 该数据给出了西瓜的诸多属性, 并提供了是\"好瓜\"还是\"坏瓜\"的标签. 我们将利用 决策树 模型来进行建模.\n\n首先我们使用 pandas 库, 导入样例数据"},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"\n     numpy version is 1.14.3\n    pandas version is 0.23.0\nmatplotlib version is 2.2.2\n"}],"source":"import numpy as np\nimport pandas as pd\nimport matplotlib as mlt\n\nlibs = [('numpy', np), ('pandas', pd), ('matplotlib', mlt)]\nprint()\nfor lib in libs:\n    print(f'{lib[0]:>10} version is {lib[1].__version__}')"},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>编号</th>\n      <th>色泽</th>\n      <th>根蒂</th>\n      <th>敲声</th>\n      <th>纹理</th>\n      <th>脐部</th>\n      <th>触感</th>\n      <th>好瓜</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>青绿</td>\n      <td>蜷缩</td>\n      <td>浊响</td>\n      <td>清晰</td>\n      <td>凹陷</td>\n      <td>硬滑</td>\n      <td>是</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>乌黑</td>\n      <td>蜷缩</td>\n      <td>沉闷</td>\n      <td>清晰</td>\n      <td>凹陷</td>\n      <td>硬滑</td>\n      <td>是</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>乌黑</td>\n      <td>蜷缩</td>\n      <td>浊响</td>\n      <td>清晰</td>\n      <td>凹陷</td>\n      <td>硬滑</td>\n      <td>是</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>青绿</td>\n      <td>蜷缩</td>\n      <td>沉闷</td>\n      <td>清晰</td>\n      <td>凹陷</td>\n      <td>硬滑</td>\n      <td>是</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>浅白</td>\n      <td>蜷缩</td>\n      <td>浊响</td>\n      <td>清晰</td>\n      <td>凹陷</td>\n      <td>硬滑</td>\n      <td>是</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>青绿</td>\n      <td>稍蜷</td>\n      <td>浊响</td>\n      <td>清晰</td>\n      <td>稍凹</td>\n      <td>软粘</td>\n      <td>是</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>乌黑</td>\n      <td>稍蜷</td>\n      <td>浊响</td>\n      <td>稍糊</td>\n      <td>稍凹</td>\n      <td>软粘</td>\n      <td>是</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8</td>\n      <td>乌黑</td>\n      <td>稍蜷</td>\n      <td>浊响</td>\n      <td>清晰</td>\n      <td>稍凹</td>\n      <td>硬滑</td>\n      <td>是</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9</td>\n      <td>乌黑</td>\n      <td>稍蜷</td>\n      <td>沉闷</td>\n      <td>稍糊</td>\n      <td>稍凹</td>\n      <td>硬滑</td>\n      <td>否</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>青绿</td>\n      <td>硬挺</td>\n      <td>清脆</td>\n      <td>清晰</td>\n      <td>平坦</td>\n      <td>软粘</td>\n      <td>否</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>11</td>\n      <td>浅白</td>\n      <td>硬挺</td>\n      <td>清脆</td>\n      <td>模糊</td>\n      <td>平坦</td>\n      <td>硬滑</td>\n      <td>否</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>12</td>\n      <td>浅白</td>\n      <td>蜷缩</td>\n      <td>浊响</td>\n      <td>模糊</td>\n      <td>平坦</td>\n      <td>软粘</td>\n      <td>否</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>13</td>\n      <td>青绿</td>\n      <td>稍蜷</td>\n      <td>浊响</td>\n      <td>稍糊</td>\n      <td>凹陷</td>\n      <td>硬滑</td>\n      <td>否</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>14</td>\n      <td>浅白</td>\n      <td>稍蜷</td>\n      <td>沉闷</td>\n      <td>稍糊</td>\n      <td>凹陷</td>\n      <td>硬滑</td>\n      <td>否</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>15</td>\n      <td>乌黑</td>\n      <td>稍蜷</td>\n      <td>浊响</td>\n      <td>清晰</td>\n      <td>稍凹</td>\n      <td>软粘</td>\n      <td>否</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>16</td>\n      <td>浅白</td>\n      <td>稍蜷</td>\n      <td>浊响</td>\n      <td>模糊</td>\n      <td>平坦</td>\n      <td>硬滑</td>\n      <td>否</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>17</td>\n      <td>青绿</td>\n      <td>稍蜷</td>\n      <td>沉闷</td>\n      <td>稍糊</td>\n      <td>稍凹</td>\n      <td>硬滑</td>\n      <td>否</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"    编号  色泽  根蒂  敲声  纹理  脐部  触感 好瓜\n0    1  青绿  蜷缩  浊响  清晰  凹陷  硬滑  是\n1    2  乌黑  蜷缩  沉闷  清晰  凹陷  硬滑  是\n2    3  乌黑  蜷缩  浊响  清晰  凹陷  硬滑  是\n3    4  青绿  蜷缩  沉闷  清晰  凹陷  硬滑  是\n4    5  浅白  蜷缩  浊响  清晰  凹陷  硬滑  是\n5    6  青绿  稍蜷  浊响  清晰  稍凹  软粘  是\n6    7  乌黑  稍蜷  浊响  稍糊  稍凹  软粘  是\n7    8  乌黑  稍蜷  浊响  清晰  稍凹  硬滑  是\n8    9  乌黑  稍蜷  沉闷  稍糊  稍凹  硬滑  否\n9   10  青绿  硬挺  清脆  清晰  平坦  软粘  否\n10  11  浅白  硬挺  清脆  模糊  平坦  硬滑  否\n11  12  浅白  蜷缩  浊响  模糊  平坦  软粘  否\n12  13  青绿  稍蜷  浊响  稍糊  凹陷  硬滑  否\n13  14  浅白  稍蜷  沉闷  稍糊  凹陷  硬滑  否\n14  15  乌黑  稍蜷  浊响  清晰  稍凹  软粘  否\n15  16  浅白  稍蜷  浊响  模糊  平坦  硬滑  否\n16  17  青绿  稍蜷  沉闷  稍糊  稍凹  硬滑  否"},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":"df = pd.read_excel('./datas/choice_watermelon.xlsx')\ndf"},{"cell_type":"markdown","execution_count":9,"metadata":{},"outputs":[{"data":{"text/plain":"0    青绿\n1    乌黑\nName: 色泽, dtype: object"},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":"## 信息熵(Information Entropy)\n\n因为后面的公式都会使用信息熵, 因此这里先介绍一下信息熵的定义.\n\n集合 $D$ 中第 $k$ 类样本所占的比率为 $p_{k} (k={1,2,...,|n|})$\n\n则 $D$ 的信息熵为: $Ent(D) = -\\displaystyle\\sum_{k=1}^{n} p_{k}\\log_{2}p_{k}$\n\ne.g. 上面样例集合 $D$ 的分类目标是属性 \"好瓜\", 该属性有两类值:\"是\"和\"否\", 因此 $n=2$ $k=1$表示\"是\", $k=2$表示\"否\", $p_1$表示\"是\"的概率, $p_2$表示\"否\"的概率, 套入信息熵公式为:\n\n$\n\\begin{align*}\n    Ent(D) &= -\\displaystyle\\sum_{k=1}^{n} p_{k}\\log_{2}p_{k} \\\\\n           &= -\\displaystyle\\sum_{k=1}^{2} p_{k}\\log_{2}p_{k} \\\\\n           &= -p_{1}\\log_{2}p_{1} - p_{2}\\log_{2}p_{2} \\\\\n           &= -\\frac{8}{17}\\log_{2}\\frac{8}{17} - \\frac{9}{17}\\log_{2}\\frac{9}{17} \\\\\n           &= 0.998\n\\end{align*}\n$\n"},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"信息熵 D 的值为: 0.9975025463691152\n"}],"source":"# 计算信息熵\nent_D = -8/17 * np.log2(8/17) - 9/17 * np.log2(9/17)\nprint(f'信息熵 D 的值为: {ent_D}')"},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":"## 信息增益(Information Gain) - ID3\n\nInformation Gain 的数据公式表示为:\n\n$\nGain(D, a) = Ent(D) - \\displaystyle \\sum_{v=1}^{V} \\frac{|D^{v}|}{|D|} Ent(D^{v})\n$\n\n- $D$: 样本集合\n- $a$: 样本集合中的某一离散属性 (e.g. 色泽)\n- $Gain(D, a)$: 属性 $a$ 的信息增益(information gain)\n- $Ent(D)$: 集合 $D$ 的信息熵(information entropy)\n- $V$: 属性 $a$ 有 $V$ 个可能的取值 $\\{a^1, a^2, ..., a^V\\}$\n- $v$: 属性 $a$ 对样本集 $D$ 进行划分, 会有 $V$ 个分支. 其中第 $v$ 个分支节点包含了样本集合 $D$ 中所有在属性 $a$ 上取值为 $a^v$ 的样本，记作 $D^v$\n- $\\frac{|D^{v}|}{|D|}$: 在属性 $a$ 上第 $v$ 个分支的权重\n- $Ent(D^{v})$: 在属性 $a$ 上第 $v$ 个分支的信息熵\n\n信息增益越大，意味着使用属性 $a$ 对样本集合 $D$ 进行划分所获得的 “纯度提升”越大, 用数学公式表示为:\n\n$\na_* = \\underset{a \\in A}{\\arg\\max} Gain(D, a)\n$\n\n根据信息增益理论, 将其应用到我们的样例中, 属性 $A = \\text{\\{'编号', '色泽', '根蒂', '敲声', '纹理', '脐部', '触感', '好瓜'\\}}$, 因为 '编号' 没有实际的意义, 我们暂且不与考虑, 因此 属性 $A = \\{a_1='色泽', \\;a_2='根蒂', \\;a_3='敲声', \\;a_4='纹理', \\;a_5='脐部', \\;a_6='触感', \\;a_7='好瓜'\\}$ 共 7 种. 在这 7 种属性中, 应该选择哪个属性最为决策树的根呢? 这就需要我们分别求出这 7 个属性的信息增益, 其中信息增益最大的那个就可以作为决策树的根属性.\n\n以属性 '色泽' 为例, 也就是需要求出 $Gain(D, a_1)$ 或 $Gain(D, '色泽')$.\n\n我们先看看一下 '色泽' 属性的数据情况"},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[{"data":{"text/plain":"0    青绿\n1    乌黑\n4    浅白\nName: 色泽, dtype: object"},"execution_count":42,"metadata":{},"output_type":"execute_result"}],"source":"# get series\ncolor_lustre = df['色泽']\n# 除重操作\ncolor_lustre.drop_duplicates()"},{"cell_type":"code","execution_count":62,"metadata":{},"outputs":[{"data":{"text/plain":"色泽  好瓜\n乌黑  否     2\n    是     4\n浅白  否     4\n    是     1\n青绿  否     3\n    是     3\nName: 编号, dtype: int64"},"execution_count":62,"metadata":{},"output_type":"execute_result"}],"source":"df.groupby(['色泽', '好瓜'])['编号'].count()"},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":"从上面的分析得出, 属性 '色泽' 去重后有三个值, 那么我们可以这么设定, $a_1='色泽'$, $a_1 = \\{a_1^1='青绿', a_1^2='乌黑', a_1^3='浅白'\\}$.\n\n这样我们就可以将样本集划分为三个子集\n\n- $D^1(色泽=青绿)$\n- $D^2(色泽=乌黑)$\n- $D^3(色泽=浅白)$\n\n现在我们分别求上述三个子集的信息熵:\n\n$\n\\begin{align*}\n    Ent(D^1) &= -\\displaystyle\\sum_{k=1}^{n}p_{k}\\log_2p_{k} \\\\\n             &= -\\displaystyle\\sum_{k=1}^{2} p_{k}\\log_{2}p_{k} \\\\\n             &= -p_{1}\\log_{2}p_{1} - p_{2}\\log_{2}p_{2} \\\\\n             &= -\\frac{3}{6}\\log_{2}\\frac{3}{6} - \\frac{3}{6}\\log_{2}\\frac{3}{6} \\\\\n             &= 1\n\\end{align*}\n$\n\n$\n\\begin{align*}\n    Ent(D^2) &= -\\displaystyle\\sum_{k=1}^{n}p_{k}\\log_2p_{k} \\\\\n             &= -\\displaystyle\\sum_{k=1}^{2} p_{k}\\log_{2}p_{k} \\\\\n             &= -p_{1}\\log_{2}p_{1} - p_{2}\\log_{2}p_{2} \\\\\n             &= -\\frac{4}{6}\\log_{2}\\frac{4}{6} - \\frac{2}{6}\\log_{2}\\frac{2}{6} \\\\\n             &= 0.918\n\\end{align*}\n$\n\n$\n\\begin{align*}\n    Ent(D^3) &= -\\displaystyle\\sum_{k=1}^{n}p_{k}\\log_2p_{k} \\\\\n             &= -\\displaystyle\\sum_{k=1}^{2} p_{k}\\log_{2}p_{k} \\\\\n             &= -p_{1}\\log_{2}p_{1} - p_{2}\\log_{2}p_{2} \\\\\n             &= -\\frac{1}{5}\\log_{2}\\frac{1}{5} - \\frac{4}{5}\\log_{2}\\frac{4}{5} \\\\\n             &= 0.722\n\\end{align*}\n$\n\n现在我们就可以求 $a_1=色泽$ 的信息熵:\n\n$\n\\begin{align*}\n    Gain(D, a_1) &= Ent(D) - \\displaystyle \\sum_{v=1}^{V} \\frac{|D^{v}|}{|D|} Ent(D^{v}) \\\\\n                 &= 0.998 - (\\frac{6}{17} \\times 1 + \\frac{6}{17} \\times 0.918 + \\frac{5}{17} \\times 0.722) \\\\\n                 &= 0.1\n\\end{align*}\n$"},{"cell_type":"code","execution_count":181,"metadata":{},"outputs":[{"data":{"text/plain":"array([9, 8])"},"execution_count":181,"metadata":{},"output_type":"execute_result"}],"source":"D = df.groupby(['好瓜']).size().values\nD"},{"cell_type":"code","execution_count":160,"metadata":{},"outputs":[{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th colspan=\"2\" halign=\"left\">count</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th colspan=\"2\" halign=\"left\">编号</th>\n    </tr>\n    <tr>\n      <th>好瓜</th>\n      <th>否</th>\n      <th>是</th>\n    </tr>\n    <tr>\n      <th>色泽</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>乌黑</th>\n      <td>2</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>浅白</th>\n      <td>4</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>青绿</th>\n      <td>3</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"   count   \n      编号   \n好瓜     否  是\n色泽         \n乌黑     2  4\n浅白     4  1\n青绿     3  3"},"execution_count":160,"metadata":{},"output_type":"execute_result"}],"source":"df2 = df.pivot_table(index=['色泽'], columns=['好瓜'], values=['编号'], aggfunc=['count'])\ndf2"},{"cell_type":"code","execution_count":179,"metadata":{},"outputs":[{"data":{"text/plain":"array([[2, 4],\n       [4, 1],\n       [3, 3]])"},"execution_count":179,"metadata":{},"output_type":"execute_result"}],"source":"a1 = df2.values\na1"},{"cell_type":"code","execution_count":182,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"[2 4] sum is 6, probility is 0.35294117647058826, entropy is 0.9182958340544896\n[4 1] sum is 5, probility is 0.29411764705882354, entropy is 0.7219280948873623\n[3 3] sum is 6, probility is 0.35294117647058826, entropy is 1.0\nD entropy is 0.9975025463691152;a1 entropy is 0.88937738110375\n"},{"data":{"text/plain":"0.1081251652653652"},"execution_count":182,"metadata":{},"output_type":"execute_result"}],"source":"def f1(x, y):\n    return (x/y) * np.log2(x/y)\n\nvf1 = np.vectorize(f1)\n\ngains = []\nfor i in a1:\n    entropy = vf1(i, i.sum()).sum() * -1\n    probility = i.sum()/a1.sum()\n    gains.append(probility * entropy)\n    print(f'{i} sum is {i.sum()}, probility is {probility}, entropy is {entropy}')\n\na1_entropy = np.array(gains).sum()\nD_entropy = vf1(D, D.sum()).sum() * -1\nprint(f'D entropy is {D_entropy};a1 entropy is {a1_entropy}')\nD_entropy - a1_entropy"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":""}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}